{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested loop exercise Musk Tweets\n",
    "\n",
    "\n",
    "We are going to be working again with a dataset containing some of Elon Musk Tweets. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Link to the dataset: https://www.kaggle.com/datasets/gpreda/elon-musk-tweets\n",
    "\n",
    "The following information is included:\n",
    "\n",
    "- ID\n",
    "- User name\n",
    "- User location\n",
    "- User description\n",
    "- User created\n",
    "- User followers\n",
    "- User friends\n",
    "- User favorites\n",
    "- User verified\n",
    "- Date\n",
    "- Text\n",
    "- Hashtags\n",
    "- Source\n",
    "- Retweets\n",
    "- Is retweet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by opening the file and examining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first tweet in the dataset:\n",
      "{'id': 1544379368478212100, 'user_name': 'Elon Musk', 'user_location': None, 'user_description': 'Mars & Cars, Chips & Dips', 'user_created': '2009-06-02 20:12:29+00:00', 'user_followers': 101240855, 'user_friends': 115, 'user_favourites': 13503, 'user_verified': True, 'date': '2022-07-05 17:55:09+00:00', 'text': '@BillyM2k I find the gold toe sock – inevitably off kilter &amp; washed out – a little troubling esthetically &amp; arguably a bit corpo', 'hashtags': None, 'source': 'Twitter for iPhone', 'retweets': 335, 'favorites': 6542, 'is_retweet': False}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    " # Opening JSON file\n",
    "f = open('extras/elon_musk_tweets.json')\n",
    "\n",
    "# We store all the tweets in a variable called Tweets\n",
    "tweets = json.load(f)\n",
    "\n",
    "\n",
    "#Let's have a look at the first Tweet\n",
    "print(\"The first tweet in the dataset:\")\n",
    "print(tweets[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**\n",
    "\n",
    "\n",
    "Let's start from the Array's last exercise. We remember that another fun method that Python offers is `split()` that allows us to transform a string into an array of words (also called tokens in NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the words in a list [\"Let's\", 'start', 'from', 'the', \"Array's\", 'last', 'exercise.', 'We', 'remember', 'that', 'another', 'fun', 'method', 'that', 'Python', 'offers', 'is', '`split()`', 'that', 'allows', 'us', 'to', 'transform', 'a', 'string', 'into', 'an', 'array', 'of', 'words']\n"
     ]
    }
   ],
   "source": [
    "example = \"Let's start from the Array's last exercise. We remember that another fun method that Python offers is `split()` that allows us to transform a string into an array of words\"\n",
    "\n",
    "words = example.split()\n",
    "\n",
    "print(\"These are the words in a list\", words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transforms the string into an array, which means we can apply all the array methods to it!\n",
    "\n",
    "**Exercise 1:** Can you use this method to calculate the average number of words that Musk uses per Tweet?\n",
    "\n",
    "Remember that in order to do that we must loop though the array of Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first 5 tweets [24, 6, 13, 5, 17]\n",
      "Average length of Tweets 10.338461538461539\n"
     ]
    }
   ],
   "source": [
    "length_of_tweets = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    tweet_tokens = tweet['text'].split()\n",
    "    len_tweet = len(tweet_tokens)\n",
    "    length_of_tweets.append(len_tweet)\n",
    "\n",
    "print(\"Length of first 5 tweets\", length_of_tweets[0:5])\n",
    "\n",
    "average_length_of_tweet = sum(length_of_tweets)/len(length_of_tweets)\n",
    "\n",
    "print(\"Average length of Tweets\", average_length_of_tweet)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some analysis at how the method `.split()` works for the Tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@BillyM2k', 'I', 'find', 'the', 'gold', 'toe', 'sock', '–', 'inevitably', 'off', 'kilter', '&amp;', 'washed', 'out', '–', 'a', 'little', 'troubling', 'esthetically', '&amp;', 'arguably', 'a', 'bit', 'corpo']\n",
      "['Sock', 'Con,', 'the', 'conference', 'for', 'socks']\n",
      "['Always', 'something', 'new', 'for', 'the', 'magazine', 'cover', 'and', 'the', 'articles', 'practically', 'write', 'themselves']\n",
      "['@ExplainThisBob', 'This', 'guy', 'gets', 'it']\n",
      "['Sock', 'tech', 'is', 'so', 'advanced', 'that', 'you', 'can', 'get', 'pretty', 'much', 'anything', 'in', 'sock', 'form', 'these', 'days!']\n",
      "['I', 'must', 'confess', 'to', 'a', 'penchant', 'for', 'creative', 'socks']\n",
      "['@slashdot', 'It’s', 'time']\n",
      "['@TonyadeVitti', '@historydefined', 'His', 'success', 'was', 'in', 'fact', 'due,', 'in', 'part,', 'because', 'he', 'was', 'super', 'fun', 'at', 'parties,', 'spoke', 'and', 'wrote', 'incredibly', 'well!']\n",
      "['@historydefined', 'While', 'bleak', 'posts', 'maybe', 'generate', 'more', 'clicks,', 'more', 'happier', 'moments', 'in', 'history', 'would', 'be', 'nice']\n",
      "['@mishaboar', '@boringcompany', 'Supporting', 'Doge', 'wherever', 'possible']\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets[0:10]:\n",
    "    print(tweet['text'].split())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to work pretty well... However we are not interested in counting the `@UserMentions` and the Hyphens (-) as words... Let's do a bit of filtering!\n",
    "\n",
    "**Exercise 2:** Let's apply what we have learnt in the tutorial about nested loops. Can you use a nested loop for calculating the average length in Musks Tweets but excluding all the user mentions and hyphens?\n",
    "\n",
    "A string method that can be useful here is `.startsWith()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m     tweet_tokens \u001b[39m=\u001b[39m tweet[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msplit()\n\u001b[1;32m      5\u001b[0m     \u001b[39m#write your code here\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m average_length_of_tweet \u001b[39m=\u001b[39m  \u001b[39msum\u001b[39;49m(length_of_tweets)\u001b[39m/\u001b[39;49m\u001b[39mlen\u001b[39;49m(length_of_tweets)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "length_of_tweets = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    tweet_tokens = tweet['text'].split()\n",
    "    #write your code here\n",
    "    \n",
    "\n",
    "average_length_of_tweet =  sum(length_of_tweets)/len(length_of_tweets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** Print some of the tweets out again and check if any other words, characters or symbols should be removed from the calculation of the average...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work a bit more easily with these tweets, let's store them as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@BillyM2k I find the gold toe sock – inevitably off kilter &amp; washed out – a little troubling esthetically &amp; arguably a bit corpo', 'Sock Con, the conference for socks', 'Always something new for the magazine cover and the articles practically write themselves', '@ExplainThisBob This guy gets it', 'Sock tech is so advanced that you can get pretty much anything in sock form these days!']\n"
     ]
    }
   ],
   "source": [
    "list_of_tweets = []\n",
    "\n",
    "for tweet in tweets: \n",
    "    list_of_tweets.append(tweet['text'])\n",
    "\n",
    "print(list_of_tweets[0:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now all tweets in a list. Let's do a bit of preprocessing and cleaning to the Tweets. \n",
    "\n",
    "This is a very common practice in NLP. The preprocessing involves:\n",
    "- lowercasing\n",
    "- removing punctuation\n",
    "- removing `&amp;`\n",
    "- splitting tweets into words\n",
    "- remove user names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'find', 'the', 'gold', 'toe', 'sock', 'inevitably', 'off', 'kilter', 'washed', 'out', 'a', 'little', 'troubling', 'esthetically', 'arguably', 'a', 'bit', 'corpo'], ['sock', 'con', 'the', 'conference', 'for', 'socks'], ['always', 'something', 'new', 'for', 'the', 'magazine', 'cover', 'and', 'the', 'articles', 'practically', 'write', 'themselves'], ['this', 'guy', 'gets', 'it'], ['sock', 'tech', 'is', 'so', 'advanced', 'that', 'you', 'can', 'get', 'pretty', 'much', 'anything', 'in', 'sock', 'form', 'these', 'days']]\n"
     ]
    }
   ],
   "source": [
    "def textPreprocessing(text):\n",
    "    text = text.lower()\n",
    "    for punc in '.,?–!':\n",
    "        text = text.replace(punc, '')\n",
    "    text = text.replace('&amp;', '')\n",
    "    text = text.split()\n",
    "    text = [w for w in text if w.startswith('@') == False]\n",
    "\n",
    "    return text\n",
    "\n",
    "nested_list_of_tweets = []\n",
    "\n",
    "for tweet in list_of_tweets:\n",
    "    preprocessed_tweet = textPreprocessing(tweet)\n",
    "    nested_list_of_tweets.append(preprocessed_tweet)\n",
    "\n",
    "print(nested_list_of_tweets[0:5])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all Tweets stored as a nested list in variable `nested_list_of_tweets`! \n",
    "\n",
    "**Exercise 4:** could you make the code above more compact by using **list comprehension**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5** Write a piece of code that gets as input a word and counts the frequency of that word across all Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (default, Apr 13 2022, 08:48:06) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8de49573b43af245f72786bba46bd0385575cfe5b71841321ea16e89eb5e3ea5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
